# 错误日志分析

> 实战指南：如何分析生产环境的错误日志和异常堆栈

## 📋 目录
- [日志分类](#日志分类)
- [日志级别](#日志级别)
- [常见错误类型](#常见错误类型)
- [日志分析工具](#日志分析工具)
- [排查流程](#排查流程)

---

## 日志分类

### 应用日志

```
✅ 业务日志
   - 业务操作记录
   - 业务异常信息
   - 关键业务节点

✅ 技术日志
   - 异常堆栈
   - 错误信息
   - 调试信息
```

### 系统日志

```
✅ 系统消息
   - /var/log/messages
   - dmesg（内核消息）
   - journalctl（systemd日志）

✅ 应用日志
   - application.log
   - error.log
   - access.log
```

### 中间件日志

```
✅ 数据库日志
   - MySQL慢查询日志
   - MySQL错误日志
   - MySQL binlog

✅ 缓存日志
   - Redis日志
   - Redis慢查询日志

✅ 消息队列日志
   - Kafka日志
   - RocketMQ日志
```

---

## 日志级别

### 标准日志级别

```
FATAL（致命）：
  - 系统无法继续运行
  - 需要立即处理
  - 例如：数据库连接失败、磁盘满

ERROR（错误）：
  - 错误但系统可以继续运行
  - 需要关注和处理
  - 例如：业务异常、数据库操作失败

WARN（警告）：
  - 潜在问题，需要关注
  - 例如：参数校验失败、连接池接近满

INFO（信息）：
  - 关键业务信息
  - 例如：用户登录、订单创建

DEBUG（调试）：
  - 调试信息
  - 生产环境通常不开启
```

---

## 常见错误类型

### 1. NullPointerException（空指针异常）

**日志特征**：
```
java.lang.NullPointerException
    at com.example.service.UserService.getUserById(UserService.java:123)
    at com.example.controller.UserController.getUser(UserController.java:45)
```

**排查方法**：
```
1. 查看堆栈信息，定位到具体代码行
2. 分析可能为null的对象
3. 检查参数校验
4. 添加防御性编程（null检查）
```

**解决方案**：
```java
// ❌ 不安全的代码
String name = user.getName().toUpperCase();

// ✅ 安全的代码
String name = user != null && user.getName() != null 
    ? user.getName().toUpperCase() 
    : "";
```

### 2. SQLException（数据库异常）

**日志特征**：
```
java.sql.SQLException: Connection is closed
    at com.mysql.jdbc.Connection.checkClosed(Connection.java:1234)
```

**常见原因**：
```
- 数据库连接关闭
- 连接池满
- 数据库服务不可用
- SQL语法错误
```

**排查方法**：
```sql
-- 查看数据库连接状态
SHOW PROCESSLIST;

-- 查看数据库错误日志
tail -f /var/log/mysql/error.log

-- 检查连接池配置
```

**解决方案**：
```
1. 检查连接池配置
2. 检查连接是否正常关闭
3. 增加连接池大小
4. 检查数据库服务状态
```

### 3. OutOfMemoryError（内存溢出）

**日志特征**：
```
java.lang.OutOfMemoryError: Java heap space
    at java.util.Arrays.copyOf(Arrays.java:3210)
    at java.util.ArrayList.grow(ArrayList.java:267)
```

**排查方法**：
```bash
# 查看堆内存使用
jmap -heap <pid>

# 查看堆内存对象统计
jmap -histo <pid>

# 生成堆转储文件
jmap -dump:format=b,file=heap.hprof <pid>

# 使用MAT分析堆转储文件
```

**解决方案**：
```
1. 增加堆内存大小（-Xmx）
2. 优化代码（减少对象创建）
3. 修复内存泄漏
4. 优化GC参数
```

### 4. TimeoutException（超时异常）

**日志特征**：
```
java.util.concurrent.TimeoutException: Read timed out
    at java.net.SocketInputStream.socketRead0(SocketInputStream.java:116)
```

**常见场景**：
```
- 数据库查询超时
- HTTP请求超时
- RPC调用超时
- 消息队列消费超时
```

**排查方法**：
```
1. 查看超时配置
2. 分析慢查询
3. 检查网络延迟
4. 查看服务负载
```

**解决方案**：
```
1. 增加超时时间（临时方案）
2. 优化慢查询（根本方案）
3. 增加重试机制
4. 使用异步处理
```

### 5. ClassNotFoundException（类找不到）

**日志特征**：
```
java.lang.ClassNotFoundException: com.example.User
    at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
```

**常见原因**：
```
- 依赖缺失
- 类路径配置错误
- 版本冲突
- 打包问题
```

**排查方法**：
```
1. 检查依赖配置
2. 查看类路径
3. 检查jar包是否完整
4. 查看Maven/Gradle依赖树
```

**解决方案**：
```
1. 添加缺失的依赖
2. 修复类路径配置
3. 解决版本冲突
4. 重新打包部署
```

---

## 日志分析工具

### 1. 命令行工具

**grep**：
```bash
# 搜索ERROR日志
grep "ERROR" application.log

# 搜索指定异常
grep "NullPointerException" application.log

# 显示上下文
grep -A 10 -B 10 "ERROR" application.log

# 统计错误数量
grep "ERROR" application.log | wc -l
```

**awk**：
```bash
# 统计错误类型
awk '/ERROR/ {print $NF}' application.log | sort | uniq -c

# 按时间统计错误
awk '/ERROR/ {print $1}' application.log | sort | uniq -c
```

**sed**：
```bash
# 提取异常堆栈
sed -n '/Exception/,/at com/p' application.log
```

### 2. 日志分析工具

**ELK Stack**：
```
- Elasticsearch：日志存储
- Logstash：日志收集
- Kibana：日志可视化
```

**Loki + Grafana**：
```
- Loki：日志聚合
- Grafana：日志可视化
```

**Splunk**：
```
- 企业级日志分析
- 强大的搜索和可视化
```

### 3. 实时日志监控

**tail**：
```bash
# 实时查看日志
tail -f application.log

# 实时查看ERROR日志
tail -f application.log | grep ERROR

# 查看最近100行
tail -n 100 application.log
```

**less**：
```bash
# 分页查看日志
less application.log

# 搜索关键字（按/）
# 向前翻页（按空格）
# 向后翻页（按b）
```

---

## 排查流程

### 第一步：收集日志

```
1. 确定问题时间范围
2. 收集相关日志文件
3. 收集错误日志和异常堆栈
4. 收集系统日志
```

### 第二步：分析日志

```
1. 搜索ERROR级别日志
2. 查看异常堆栈
3. 统计错误频率
4. 分析错误模式
```

### 第三步：定位问题

```
1. 查看堆栈信息，定位代码行
2. 分析错误原因
3. 查看相关代码
4. 复现问题（如果可能）
```

### 第四步：解决问题

```
1. 修复代码bug
2. 优化配置
3. 增加防御性编程
4. 添加监控告警
```

---

## 日志分析最佳实践

### 1. 日志格式规范

**结构化日志**：
```java
// ✅ 使用结构化日志
log.info("用户登录成功, userId={}, ip={}, time={}", 
    userId, ip, System.currentTimeMillis());

// ❌ 避免字符串拼接
log.info("用户登录成功, userId=" + userId + ", ip=" + ip);
```

### 2. 日志级别使用

```
✅ FATAL：系统无法继续运行
✅ ERROR：错误但可以继续运行
✅ WARN：潜在问题
✅ INFO：关键业务信息
✅ DEBUG：调试信息（生产环境关闭）
```

### 3. 异常处理

```java
// ✅ 记录完整异常信息
try {
    // 业务逻辑
} catch (Exception e) {
    log.error("处理订单失败, orderId={}", orderId, e);
    throw new BusinessException("订单处理失败", e);
}
```

### 4. 日志监控告警

```
✅ ERROR级别日志 → 立即告警
✅ WARN级别日志 → 告警（可配置阈值）
✅ 异常频率统计 → 告警
✅ 关键业务日志 → 监控
```

---

## 错误日志具体案例分析

### 案例一：日志风暴导致磁盘空间耗尽

**问题描述**：生产环境某服务突然不可用，排查发现磁盘空间被占满，罪魁祸首是短时间内产生的大量ERROR级别日志。

**日志特征**：
```
2025-12-26 08:30:00 ERROR [pool-1-thread-1] com.example.service.PaymentService - 支付处理失败: null
2025-12-26 08:30:00 ERROR [pool-1-thread-2] com.example.service.PaymentService - 支付处理失败: null
2025-12-26 08:30:00 ERROR [pool-1-thread-3] com.example.service.PaymentService - 支付处理失败: null
...（每分钟产生10万+条错误日志）
```

**根本原因**：第三方支付接口异常返回null，代码未做空值判断，导致循环调用中持续抛出NPE并记录ERROR日志。

**解决方案**：
```java
// 1. 添加空值保护
if (paymentResult == null) {
    log.warn("支付接口返回空值, userId={}", userId); // 使用WARN级别而非ERROR
    return handlePaymentFallback(userId); // 触发降级策略
}

// 2. 添加限流保护
RateLimiter rateLimiter = RateLimiter.create(100.0); // 限制日志输出速率
if (rateLimiter.tryAcquire() && log.isErrorEnabled()) {
    log.error("支付处理失败: {}", e.getMessage());
}
```

**预防措施**：
```bash
# 1. 配置日志轮转策略
cat /etc/logrotate.d/application
/application/logs/*.log {
    daily
    rotate 7
    size 100M
    missingok
    compress
    delaycompress
    notifempty
}

# 2. 设置磁盘空间监控告警
```

### 案例二：多系统日志关联分析

**问题描述**：用户下单后支付成功但订单状态未更新，涉及订单系统、支付系统和库存系统，单系统日志无法定位问题。

**排查方法**：使用分布式追踪ID关联多系统日志

**实现方案**：
```java
// 使用MDC传递追踪ID
public class TraceIdFilter implements Filter {
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) {
        String traceId = UUID.randomUUID().toString();
        MDC.put("traceId", traceId);
        try {
            chain.doFilter(request, response);
        } finally {
            MDC.remove("traceId");
        }
    }
}

// 日志输出格式配置
<PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss} [%X{traceId}] [%t] %-5level %logger{36} - %msg%n"/>
```

**查询示例**：
```bash
# 使用ELK查询特定traceId的所有日志
curl -XGET "http://elasticsearch:9200/_search" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "traceId": "f47ac10b-58cc-4372-a567-0e02b2c3d479"
    }
  }
}'
```

---
## 高级日志排查技术

### ELK Stack日志聚合分析

**架构组件**：
- Elasticsearch: 日志存储与检索
- Logstash: 日志收集与处理
- Kibana: 日志可视化与分析

**Filebeat配置示例**：
```yaml
filebeat.inputs:
- type: log
  paths:
    - /application/logs/*.log
  fields:
    service: order-service
    environment: production

output.logstash:
  hosts: ["logstash:5044"]
```

**Logstash配置示例**：
```ruby
input {
  beats {
    port => 5044
  }
}

filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:traceId}\] \[%{DATA:thread}\] %{LOGLEVEL:level} %{DATA:logger} - %{DATA:message}" }
  }
  date {
    match => ["timestamp", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "application-logs-%{+YYYY.MM.dd}"
  }
}
```

**Kibana查询示例**：
```
level:ERROR AND service:order-service AND @timestamp:[now-1h TO now]
```

### Loki + Grafana日志监控

**部署配置**：
```yaml
# docker-compose.yml
version: '3'
services:
  loki:
    image: grafana/loki:2.4.0
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config.yml:/etc/loki/local-config.yml
    command: -config.file=/etc/loki/local-config.yml

  promtail:
    image: grafana/promtail:2.4.0
    volumes:
      - ./promtail-config.yml:/etc/promtail/config.yml
      - /application/logs:/var/logs
    command: -config.file=/etc/promtail/config.yml

  grafana:
    image: grafana/grafana:8.2.0
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=secret
```

**Promtail配置**：
```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
- job_name: system
  static_configs:
  - targets:
      - localhost
    labels:
      job: application-logs
      __path__: /var/logs/*.log
```

**Grafana查询示例**：
```logql
{job="application-logs"} |= "ERROR"
```

---
## 日志监控告警配置

### Prometheus + Grafana监控

**Prometheus配置**：
```yaml
scrape_configs:
  - job_name: 'log_exporter'
    static_configs:
      - targets: ['log-exporter:9104']

rule_files:
  - "alert.rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093
```

**告警规则配置**：
```yaml
groups:
- name: log_alerts
  rules:
  - alert: HighErrorRate
    expr: sum(rate(log_messages{level=~"ERROR|FATAL"}[5m])) / sum(rate(log_messages[5m])) > 0.05
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "高错误日志率"
      description: "错误日志占比超过5%持续2分钟 (当前值: {{ $value }})"

  - alert: LogVolumeSpike
    expr: sum(rate(log_messages[5m])) > 2 * sum(rate(log_messages[30m]))
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "日志量突增"
      description: "日志量较30分钟平均值增长超过2倍 (当前值: {{ $value }})"
```

### 日志异常检测

**基于机器学习的日志异常检测**：
```python
# 使用LogAnomaly进行日志异常检测
from sklearn.ensemble import IsolationForest
import numpy as np

# 日志特征向量
log_features = np.array([...])  # 提取的日志特征

# 训练异常检测模型
model = IsolationForest(contamination=0.01)
model.fit(log_features)

# 预测异常日志
predictions = model.predict(new_log_features)
```

---
## 生产环境日志最佳实践

### 1. 日志安全

```
✅ 敏感信息脱敏
  - 用户密码、身份证号、银行卡号等
  - 使用正则表达式替换敏感信息

✅ 日志访问控制
  - 限制日志文件访问权限
  - 日志系统认证授权
```

### 2. 日志性能优化

```
✅ 异步日志
  - 使用Disruptor等高性能日志框架
  - 避免日志输出阻塞业务线程

✅ 日志采样
  - 高并发场景下采样输出DEBUG日志
  - 例如：每100条采样1条
```

### 3. 日志成本控制

```
✅ 日志分级存储
  - 热数据：高性能存储（7天）
  - 温数据：普通存储（30天）
  - 冷数据：归档存储（1年+）

✅ 日志压缩
  - 使用gzip压缩历史日志
  - 降低存储成本
```

---
## 相关工具推荐

| 工具 | 用途 | 优势 |
|------|------|------|
| ELK Stack | 日志聚合分析 | 功能全面，生态完善 |
| Loki + Grafana | 轻量级日志监控 | 资源占用低，易于部署 |
| Graylog | 日志管理平台 | 内置告警，用户友好 |
| Splunk | 企业级日志分析 | 搜索能力强，可视化丰富 |
| Fluentd | 日志收集 | 插件丰富，性能优异 |

---
**文档状态**：内容完善中 - 已补充案例分析、高级技术和监控告警配置