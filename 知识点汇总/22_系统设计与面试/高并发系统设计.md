# 高并发系统设计

> 大厂面试必考：如何设计支持百万、千万级QPS的高并发系统

## 📋 目录
- [高并发核心指标](#高并发核心指标)
- [高并发系统设计原则](#高并发系统设计设计原则)
- [高并发解决方案](#高并发解决方案)
- [典型高并发场景](#典型高并发场景)
- [性能优化实战](#性能优化实战)

---

## 高并发核心指标

### 1. 性能指标

**QPS（Queries Per Second）**：
```
QPS = 总请求数 / 时间

示例：
  1万QPS   = 一般中小型系统
  10万QPS  = 大型系统
  100万QPS = 超大型系统（淘宝、抖音）
```

**RT（Response Time）响应时间**：
```
P50: 50%请求的响应时间
P90: 90%请求的响应时间（9成用户体验）
P99: 99%请求的响应时间（关注长尾）
P999: 99.9%请求的响应时间

理想值：
  P99 < 100ms  ：优秀
  P99 < 500ms  ：良好
  P99 > 1000ms ：需优化
```

**TPS（Transactions Per Second）**：
```
TPS = 完成的事务数 / 时间

与QPS区别：
  QPS：所有请求（包括失败）
  TPS：成功的业务事务
```

**并发量**：
```
并发量 = QPS × RT

示例：
  QPS = 10000，RT = 0.1s
  并发量 = 10000 × 0.1 = 1000
  需要系统能同时处理1000个请求
```

### 2. 可用性指标

**可用性计算**：
```
可用性 = (总时间 - 故障时间) / 总时间 × 100%

常见标准：
  99%     = 2个9 = 年故障时间 3.65天
  99.9%   = 3个9 = 年故障时间 8.76小时
  99.99%  = 4个9 = 年故障时间 52.6分钟 ⭐
  99.999% = 5个9 = 年故障时间 5.26分钟

大厂要求：
  核心服务：4个9（99.99%）
  一般服务：3个9（99.9%）
```

---

## 高并发系统设计原则

### 1. 无状态化

**为什么无状态**：
```
有状态服务的问题：
  ❌ 无法水平扩展
  ❌ 负载均衡受限
  ❌ 节点故障影响用户

无状态服务的优势：
  ✅ 任意节点可处理请求
  ✅ 水平扩展简单
  ✅ 负载均衡灵活
```

**如何无状态化**：
```java
// ❌ 有状态（Session存本地）
@Controller
public class UserController {
    private Map<String, User> sessionCache = new HashMap<>();
    
    public void login(User user) {
        sessionCache.put(user.getId(), user);  // 问题！
    }
}

// ✅ 无状态（Session存Redis）
@Controller
public class UserController {
    @Autowired
    private RedisTemplate redisTemplate;
    
    public void login(User user) {
        redisTemplate.opsForValue().set(
            "session:" + user.getId(), 
            user, 
            30, TimeUnit.MINUTES
        );
    }
}
```

### 2. 拆分原则

**垂直拆分（按业务）**：
```
单体应用：
  用户模块 + 订单模块 + 商品模块

拆分后：
  用户服务
  订单服务
  商品服务

优势：
  ✅ 职责清晰
  ✅ 独立部署
  ✅ 技术栈灵活
```

**水平拆分（按数据）**：
```
单库单表：
  orders表（1亿条记录） → 查询慢

分库分表：
  DB0: orders_0, orders_1
  DB1: orders_2, orders_3
  DB2: orders_4, orders_5

优势：
  ✅ 分散压力
  ✅ 提升性能
  ✅ 易扩展
```

### 3. 异步化原则

**同步 vs 异步**：
```
同步处理（串行）：
  创建订单(50ms) → 扣库存(30ms) → 发短信(100ms) → 积分(20ms)
  总耗时：200ms

异步处理（并行）：
  创建订单(50ms) → 返回
  └→ MQ → [扣库存, 发短信, 积分] 并行处理
  总耗时：50ms ✅
```

**实现方式**：
```
1. 消息队列：Kafka、RocketMQ
2. 线程池：CompletableFuture
3. Event-Driven：事件驱动架构
```

### 4. 缓存优先

**多级缓存架构**：
```
客户端 → CDN(命中率90%) 
       → Nginx本地缓存(命中率5%)
       → Redis集群(命中率4.5%)
       → 数据库(0.5%)

总体缓存命中率：99.5% ✅
```

---

## 高并发解决方案

### 1. 前端优化

**静态化**：
```html
<!-- 动态页面 → 静态页面 -->
<!-- ❌ 每次请求服务器渲染 -->
<div>当前商品库存：${stock}</div>

<!-- ✅ 静态HTML + AJAX动态加载 -->
<div>当前商品库存：<span id="stock">加载中...</span></div>
<script>
  fetch('/api/stock/123').then(data => {
    document.getElementById('stock').innerText = data.stock;
  });
</script>
```

**CDN加速**：
```
用户(北京) → CDN节点(北京) ✅ 10ms
            ↓ 未命中
            源站(深圳) 50ms

直接访问源站：60ms
通过CDN访问：10ms（命中）
```

**资源优化**：
```
1. 图片压缩、懒加载
2. JS/CSS压缩、合并
3. Gzip压缩传输
4. HTTP/2多路复用
5. 浏览器缓存
```

### 2. 接入层优化

**负载均衡策略**：
```
轮询（Round Robin）：
  请求1 → 服务器A
  请求2 → 服务器B
  请求3 → 服务器C
  
加权轮询：
  服务器A(权重3) → 30%流量
  服务器B(权重2) → 20%流量
  服务器C(权重5) → 50%流量
  
最少连接（Least Connections）：
  选择当前连接数最少的服务器
  
一致性Hash：
  同一用户路由到同一服务器
```

**限流保护**：
```java
// 单机限流：Guava RateLimiter
RateLimiter limiter = RateLimiter.create(1000);  // 1000 QPS
if (limiter.tryAcquire()) {
    // 处理请求
} else {
    return "系统繁忙，请稍后重试";
}

// 分布式限流：Redis + Lua
String script = 
    "local key = KEYS[1] " +
    "local limit = tonumber(ARGV[1]) " +
    "local current = tonumber(redis.call('get', key) or '0') " +
    "if current + 1 > limit then " +
    "    return 0 " +
    "else " +
    "    redis.call('INCRBY', key, 1) " +
    "    redis.call('EXPIRE', key, 1) " +
    "    return 1 " +
    "end";
```

### 3. 应用层优化

**连接池复用**：
```java
// ❌ 每次创建连接
public void query() {
    Connection conn = DriverManager.getConnection(url);
    // 执行查询
    conn.close();  // 性能差！
}

// ✅ 连接池复用
@Autowired
private DataSource dataSource;

public void query() {
    Connection conn = dataSource.getConnection();
    // 执行查询
    conn.close();  // 实际归还连接池
}
```

**批量处理**：
```java
// ❌ 循环单条插入
for (User user : users) {
    userMapper.insert(user);  // N次数据库调用
}

// ✅ 批量插入
userMapper.batchInsert(users);  // 1次数据库调用
```

**并行处理**：
```java
// ❌ 串行调用
User user = userService.getUser(userId);        // 50ms
List<Order> orders = orderService.getOrders();  // 50ms
Product product = productService.getProduct();  // 50ms
// 总耗时：150ms

// ✅ 并行调用
CompletableFuture<User> userFuture = 
    CompletableFuture.supplyAsync(() -> userService.getUser(userId));
CompletableFuture<List<Order>> ordersFuture = 
    CompletableFuture.supplyAsync(() -> orderService.getOrders());
CompletableFuture<Product> productFuture = 
    CompletableFuture.supplyAsync(() -> productService.getProduct());

CompletableFuture.allOf(userFuture, ordersFuture, productFuture).join();
// 总耗时：50ms ✅
```

### 4. 缓存层优化

**缓存策略**：
```
Read-Through（读穿透）：
  应用 → 缓存层 → (未命中) → DB → 缓存层 → 应用
  
Write-Through（写穿透）：
  应用 → 缓存层 → DB（同步写）
  
Write-Behind（写回）：
  应用 → 缓存 → 返回
         ↓ 异步
         DB（批量写）⭐ 高性能
```

**热点数据处理**：
```java
// 本地缓存 + Redis缓存
@Cacheable(value = "hotData", key = "#id")
public Data getHotData(String id) {
    // 先查本地缓存（Caffeine）
    Data data = localCache.get(id);
    if (data != null) return data;
    
    // 再查Redis
    data = redis.get(id);
    if (data != null) {
        localCache.put(id, data);  // 放入本地缓存
        return data;
    }
    
    // 最后查DB
    data = db.query(id);
    redis.set(id, data, 3600);
    localCache.put(id, data);
    return data;
}
```

### 5. 数据库优化

**读写分离**：
```
              ┌──→ 从库1(读) ─┐
写请求 → 主库  ├──→ 从库2(读) ├→ 90%读流量
              └──→ 从库3(读) ─┘
              
主从延迟处理：
  1. 强一致要求 → 主库读
  2. 最终一致 → 从库读
  3. 延迟补偿 → 先查缓存
```

**分库分表**：
```java
// 分片规则
public class ShardingStrategy {
    // 按用户ID Hash分库
    public int getDbIndex(Long userId) {
        return (int) (userId % 8);  // 8个库
    }
    
    // 按时间Range分表
    public String getTableName(Date date) {
        return "orders_" + DateUtil.format(date, "yyyyMM");
    }
}
```

**SQL优化**：
```sql
-- ❌ 慢查询
SELECT * FROM orders WHERE status = 1 AND user_id = 123;

-- ✅ 添加联合索引
CREATE INDEX idx_status_userid ON orders(status, user_id);

-- ❌ 全表扫描
SELECT * FROM orders WHERE DATE(create_time) = '2025-10-29';

-- ✅ 使用索引
SELECT * FROM orders WHERE create_time >= '2025-10-29 00:00:00' 
AND create_time < '2025-10-30 00:00:00';
```

### 6. 消息队列削峰

**削峰填谷**：
```
瞬时流量：10万QPS
          ↓
消息队列：缓冲
          ↓
消费端：匀速1万QPS处理

保护下游系统 ✅
```

**异步解耦**：
```
订单服务 → MQ → [库存服务, 积分服务, 通知服务]

优势：
  ✅ 服务解耦
  ✅ 异步处理
  ✅ 流量削峰
  ✅ 失败重试
```

---

## 典型高并发场景

### 场景1：秒杀系统

**核心挑战**：
```
瞬时高并发：100万用户抢100个商品
读多写少：查询库存 >> 下单
超卖问题：库存扣减并发控制
```

**解决方案**：
```
1. 前端：
   - 答题验证码（过滤机器人）
   - 按钮倒计时（防重复点击）
   
2. 接入层：
   - Nginx限流
   - 按用户ID限流
   
3. 业务层：
   - Redis预减库存
   - 消息队列异步下单
   
4. 数据层：
   - 数据库乐观锁
   UPDATE stock SET count = count - 1 
   WHERE id = 1 AND count > 0
```

详见：[02_设计秒杀系统.md](./经典系统设计案例/02_设计秒杀系统.md)

### 场景2：抢红包系统

**核心挑战**：
```
高并发：瞬间几千人抢
随机金额：红包金额随机分配
原子性：红包不能超发
```

**解决方案**：
```
1. 预分配算法：
   总金额100元，10个红包
   → 预先计算每个红包金额
   [8.5, 12.3, 9.8, ...]
   
2. Redis原子操作：
   LPOP red_packet:123  # 原子弹出
   
3. 库存扣减：
   Lua脚本保证原子性
```

详见：[06_设计抢红包系统.md](./经典系统设计案例/06_设计抢红包系统.md)

### 场景3：Feed流系统

**核心挑战**：
```
读多写少：10:1甚至100:1
实时性：发布后立即可见
个性化：每个用户看到的不同
```

**解决方案**：
```
推模式（写扩散）：
  用户A发布 → 推送到所有粉丝的收件箱
  ✅ 读快
  ❌ 写慢（大V问题）
  
拉模式（读扩散）：
  用户B刷新 → 拉取关注列表的最新动态
  ✅ 写快
  ❌ 读慢
  
推拉结合（推荐）：
  普通用户：推模式
  大V用户：拉模式
```

详见：[04_设计feed流系统.md](./经典系统设计案例/04_设计feed流系统.md)

---

## 性能优化实战

### 1. JVM优化

**GC调优**：
```bash
# 查看GC情况
jstat -gcutil <pid> 1000

# G1 GC参数（推荐）
-XX:+UseG1GC
-XX:MaxGCPauseMillis=200        # 最大GC停顿200ms
-XX:G1HeapRegionSize=16M        # Region大小
-XX:InitiatingHeapOccupancyPercent=45  # GC触发阈值

# 堆大小设置
-Xms4g -Xmx4g                   # 初始和最大堆一致
-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m
```

**OOM排查**：
```bash
# 生成堆转储文件
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=/tmp/heapdump.hprof

# MAT分析工具
1. 查找大对象
2. 分析引用链
3. 找到内存泄漏点
```

### 2. 数据库优化

**慢SQL排查**：
```sql
-- 开启慢查询日志
SET GLOBAL slow_query_log = ON;
SET GLOBAL long_query_time = 1;  -- 1秒

-- 分析慢SQL
EXPLAIN SELECT * FROM orders WHERE user_id = 123;

-- 优化建议
1. 添加索引
2. 避免SELECT *
3. 分页优化（深分页问题）
4. 避免函数计算
```

**索引优化**：
```sql
-- ❌ 函数破坏索引
WHERE DATE(create_time) = '2025-10-29'

-- ✅ 改写SQL
WHERE create_time >= '2025-10-29 00:00:00' 
AND create_time < '2025-10-30 00:00:00'

-- ❌ 隐式类型转换
WHERE user_id = '123'  -- user_id是BIGINT

-- ✅ 类型匹配
WHERE user_id = 123
```

### 3. Redis优化

**大key问题**：
```bash
# 查找大key
redis-cli --bigkeys

# 解决方案
1. 拆分大key：String → Hash分片
2. 设置过期时间
3. 异步删除：UNLINK代替DEL
```

**热key问题**：
```
解决方案：
1. 本地缓存（Caffeine）
2. 主从读写分离
3. key分片：key → key#1, key#2, key#3
```

### 4. 网络优化

**HTTP优化**：
```
1. 开启Gzip压缩
2. HTTP/2（多路复用、头部压缩）
3. Keep-Alive（长连接）
4. 合并请求（批量接口）
```

**TCP优化**：
```bash
# 调整内核参数
net.ipv4.tcp_tw_reuse = 1       # TIME_WAIT复用
net.core.somaxconn = 65535      # 监听队列
net.ipv4.tcp_max_syn_backlog = 8192  # SYN队列
```

---

## 📊 性能评估

### 压测工具

**JMeter压测**：
```
1. 设置线程数：1000
2. 设置循环次数：10
3. 添加监听器：聚合报告
4. 查看TPS、RT、错误率
```

**ab压测**：
```bash
# 100并发，总共1000请求
ab -c 100 -n 1000 http://example.com/api

# 查看结果
Requests per second: 5000 [#/sec]  # QPS
Time per request: 20 [ms]  # RT
```

### 性能基准

**典型性能指标**：
```
接口RT：
  P99 < 50ms   ：优秀
  P99 < 100ms  ：良好
  P99 < 500ms  ：一般
  P99 > 1000ms ：差

数据库查询：
  简单查询 < 10ms
  复杂查询 < 100ms
  
缓存访问：
  Redis < 1ms
  本地缓存 < 0.1ms
```

---

## 📚 总结

### 高并发设计核心

```
1. 分层设计：前端 → 接入 → 应用 → 缓存 → 数据库
2. 水平扩展：无状态、分库分表、集群部署
3. 缓存为王：多级缓存、高命中率
4. 异步解耦：消息队列、事件驱动
5. 限流降级：保护系统、优雅降级
```

### 性能优化顺序

```
1. 先加缓存（性价比最高）
2. 再优化SQL（索引、分库分表）
3. 然后异步化（消息队列）
4. 最后考虑架构（微服务、分布式）
```

### 面试要点

```
1. 理解核心指标（QPS、RT、并发量）
2. 掌握经典方案（缓存、异步、分库分表）
3. 结合实际案例（秒杀、抢红包、Feed流）
4. 说明权衡取舍（一致性 vs 性能）
```

---

## 📖 相关文档

- [系统设计方法论](./系统设计方法论.md)
- [02_设计秒杀系统](./经典系统设计案例/02_设计秒杀系统.md)
- [04_设计feed流系统](./经典系统设计案例/04_设计feed流系统.md)

---

**最后更新**: 2025-10-29  
**文档状态**: ✅ 核心内容已完成

💡 **记住**: 高并发不是堆硬件，而是合理的架构设计和优化策略！
